{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scrapping - Berlin Restaurants\n",
    "\n",
    "Source webpage: *https://www.berlin.de/restaurants/stadtteile/*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Importing python libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Declaring functions get detail data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract restaurant name\n",
    "def get_name(soup):\n",
    "    \n",
    "    try:\n",
    "        link_restaurant = soup.find('section', class_ = 'block befi-address')\n",
    "        restaurant_name_tag = link_restaurant.find('div')\n",
    "        restaurant_name = restaurant_name_tag.text.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        restaurant_name = \"\"\n",
    "\n",
    "    return restaurant_name\n",
    "\n",
    "# Function to extract restaurant address\n",
    "def get_address(soup):\n",
    "    \n",
    "    try:\n",
    "        link_restaurant = soup.find('section', class_ = 'block befi-address')\n",
    "        restaurant_name_tag = link_restaurant.find('div')\n",
    "        restaurant_address_tag = restaurant_name_tag.find_next('div')\n",
    "        restaurant_address = restaurant_address_tag.text.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        restaurant_address = \"\"\n",
    "\n",
    "    return restaurant_address\n",
    "\n",
    "# Function to extract restaurant zip\n",
    "def get_zip(soup):\n",
    "    \n",
    "    try:\n",
    "        link_restaurant = soup.find('section', class_ = 'block befi-address')\n",
    "        restaurant_zip_tag = link_restaurant.find('span')\n",
    "        restaurant_zip = restaurant_zip_tag.text.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        restaurant_zip = \"\"\n",
    "\n",
    "    return restaurant_zip\n",
    "\n",
    "# Function to extract restaurant phone\n",
    "def get_phone(soup):\n",
    "    \n",
    "    try:\n",
    "        link_restaurant = soup.find('section', class_ = 'block befi-address')\n",
    "        restaurant_zip_tag = link_restaurant.find('span')\n",
    "        restaurant_phone_tag = restaurant_zip_tag.find_next('a')\n",
    "        restaurant_phone = restaurant_phone_tag.text.strip()\n",
    "        if not restaurant_phone.startswith(\"(\"):\n",
    "            restaurant_phone = \"None\"\n",
    "\n",
    "    except AttributeError:\n",
    "        restaurant_phone = \"None\"\n",
    "\n",
    "    return restaurant_phone\n",
    "\n",
    "# Function to extract restaurant type\n",
    "def get_type(link):\n",
    "    \n",
    "    try:\n",
    "        # Finding the restaurant type in http address (link)\n",
    "        text = (link.split(\"adressen/\",1)[1]).split(\"/\",1)[0]\n",
    "\n",
    "        # Splitting and merging text to get correct string type\n",
    "        splittet_text = text.split('-',1)\n",
    "        if len(splittet_text) == 1:\n",
    "            restaurant_type = splittet_text[0].capitalize()\n",
    "        else:\n",
    "            restaurant_type = splittet_text[0].capitalize() + ' ' + splittet_text[1].capitalize()\n",
    "\n",
    "    except AttributeError:\n",
    "        restaurant_type = \"None\"\n",
    "\n",
    "    return restaurant_type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Main program:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    # Headers for request\n",
    "    HEADERS = ({'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36', 'Accept-Language': 'en-US, en;q=0.5'})\n",
    "    \n",
    "    # Selecting main page\n",
    "    page_url = \"https://www.berlin.de/restaurants/stadtteile/\"\n",
    "    page = requests.get(page_url, headers=HEADERS)\n",
    "\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "\n",
    "    # Finding links for each cityzone\n",
    "    page_list_zones = soup.find_all('h3', class_ = 'title')\n",
    "\n",
    "    # Iterate over the <h3> elements and find the nested <a> elements\n",
    "    # and creating sublinks for each cityzone\n",
    "    zone_sublinks = []\n",
    "\n",
    "    for h3 in page_list_zones:\n",
    "        a_elements = h3.find_all('a')\n",
    "        for a in a_elements:\n",
    "            zone_sublinks.append(a['href'])\n",
    "\n",
    "    # Getting all subzones placed just in Berlin\n",
    "    zone_sublinks = zone_sublinks[:23]\n",
    "\n",
    "    # Creating complete links for each cityzone\n",
    "    zone_links = []\n",
    "\n",
    "    for zone in zone_sublinks:\n",
    "        zone_page_url = 'https://www.berlin.de' + zone\n",
    "        zone_links.append(zone_page_url)\n",
    "\n",
    "    # Creating empty list for links of all restaurant separately\n",
    "    all_restaurants_list = []\n",
    "\n",
    "\n",
    "    # Finding links for each restaurant in each cityzone\n",
    "    def find_restaurant_links(zone_link):\n",
    "        # Opening page of each restaurant\n",
    "        zone_page = requests.get(zone_link)\n",
    "        local_soup = BeautifulSoup(zone_page.content, 'html.parser')\n",
    "        #print(local_soup.prettify())\n",
    "        # Finding links for each restarant from each zone by searching specific \"text\" in hrefs\n",
    "        restaurant_sublink = local_soup.find_all('a', href=lambda href: href and \"restaurants/adressen\" in href and \"html\" in href)\n",
    "\n",
    "        # Creating temporary list of sublinks for each zone\n",
    "        subzone_sublinks = []\n",
    "\n",
    "        # Adding all sublinks info list\n",
    "        for el in restaurant_sublink:\n",
    "            subzone_sublinks.append(el['href'])\n",
    "\n",
    "        # Adding \"htpps - prefix\" for each link\n",
    "        for zone in subzone_sublinks:\n",
    "            zone_page_url = 'https://www.berlin.de' + zone\n",
    "            all_restaurants_list.append(zone_page_url)\n",
    "        #print(len(all_restaurants_list))\n",
    "\n",
    "        return all_restaurants_list\n",
    "\n",
    "\n",
    "    # Looping through all zones\n",
    "    for link in zone_links:\n",
    "        find_restaurant_links(link)\n",
    "\n",
    "    # Number of the restaurants\n",
    "    len(all_restaurants_list)\n",
    "\n",
    "    # Creating the dictionary schema\n",
    "    result = {'Name': [], 'Restaurant_Type': [], 'Address': [], 'Zip_Code': [], 'Phone': []}\n",
    "\n",
    "    # Looping for extracting details from each link\n",
    "    for link in all_restaurants_list:\n",
    "        new_page = requests.get(link, headers=HEADERS)\n",
    "        new_soup = BeautifulSoup(new_page.content, 'html.parser')\n",
    "\n",
    "        result['Name'].append(get_name(new_soup))\n",
    "        result['Restaurant_Type'].append(get_type(link))\n",
    "        result['Address'].append(get_address(new_soup))\n",
    "        result['Zip_Code'].append(get_zip(new_soup))\n",
    "        result['Phone'].append(get_phone(new_soup))\n",
    "\n",
    "    # Creating pandas dataframe\n",
    "    dataset_restaurants = pd.DataFrame.from_dict(result)\n",
    "\n",
    "    # Exporting dataset as .csv file\n",
    "    dataset_restaurants.to_csv('dataset_berlin_restaurants.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cef1d38ca744d99e247d6c4d165e12a9aa3f29f1e83d9722af487dd60dc4e580"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
